---
title: "Final Data Preparation"
author: "Nicole Barker"
date: "Last run: Jan 4, 2018"
output: 
  word_document:
    reference_docx: ../styles/ReportFormat_1.docx
---

## Script Abstract

## Background
In previous steps: 

* I added offsets into the table
* I filtered dates based on mismatch between VRI data and bird surveys
* I expect to filter based on proximity of point count to stand edge once that data is available. NOT CURRENTLY DONE. 

However, I still need to do a bit more data processing before I can do analyses. 


In this script: 

* Subset to desired behaviours
* I sum across species to develop a total bird count per survey 
* I explore relationships between project (PCODE) and apparent total bird count

**NOTE: I also plan to filter based on proximity of a point count to the stand edge (in a previous step), but I don't have the necessary information from Trish for that yet**

``` {r setup, echo=F, message=F, warning=F}
require(knitr)
opts_knit$set(root.dir = '..')
knitr::opts_chunk$set(
  fig.path = "figures/"
)
```

``` {r load.project, message=F}
require(ProjectTemplate)
load.project()
options(digits=12)
```

### Subset to columns needed for exploration of bird counts per different survey methods

``` {r}
load("cache/vri_bird_tempaligned.RData") #(PKEYs quality-checked for use)
colnames(vri_bird_tempaligned)
#load("cache/vri_bird_tempaligned-distfiltered.RData") # this doesn't exist yet

tmp <- read.csv("data/birddata_preprocess1.csv", header=T) # fuller bird dataset (with survey method details)

birddat <- merge(vri_bird_tempaligned[c("PKEY")], tmp, by="PKEY", all.x=T)
```

### Subset to desired behaviours 

Following Peter Solymos's guidelines (https://github.com/psolymos/bamanalytics/blob/master/R/dataprocessing.R) and keeping behaviours 1, 6, and 11. See table below for definitions. 

``` {r}
t.behav <- data.frame(table(birddat$BEH))
colnames(t.behav) <- c("behcode", "NumObservations")

lookup.behav <- read.csv("data/LOOKUP.BehaviourCodes.csv", header=T)
lookup.behav <- lookup.behav[order(lookup.behav$behcode),]

t.behav <- merge(lookup.behav, t.behav, all=T)
t.behav$NumObservations[is.na(t.behav$NumObservations)] <- 0
kable(t.behav, row.names=F)

birddat2 <- birddat[birddat$BEH %in% c("1", "6", "11"),]
```

### Add methodologies

Need to load method details from the projects summary and the definitions/descriptions of each duration and distance method code. 

``` {r}
projs <- read.csv("data/National_Proj_Summary_V4_2015.csv", header=T)
colnames(projs)[which(colnames(projs) == "Method")] <- "METHOD" #change colname
projs$Maxdist <- toupper(projs$Maxdist)

birddat3 <- merge(birddat2, projs[c("METHOD", "MaxDuration", "Maxdist")], by="METHOD", all.x = T)
kable(head(birddat3))
```

**NOTES**

* And here is where I realized that some of the new projects don't have max dist and max duration in their tables
* I referred back to the Access database to update the project summary table accordingly

``` {r}
meths <- read.csv("data/qry_ProjMethodSummary-manuallyCorrected.csv", header=T)

birddat3.5 <- merge(birddat3[c("METHOD", "PKEY", "SS", "SITE", "STN", "YYYY", "MM", "DD", "StartTime", "SPECIES", "English_Name", "BEH", "ABUND")], meths[c("METHOD", "DURMETH", "DURATIONRANGE", "DISTMETH", "DISTANCERANGE", "MaxDuration", "Maxdist")], by="METHOD", all.x=T)
```

#### Reclass methods to the subset I would use as factors in subsequent analyses

``` {r}
distanceClass <- data.frame(Maxdist=unique(birddat3.5$Maxdist), distanceClass=c("unlimited", "80-100", "80-100", "50"))

durationClass <- data.frame(MaxDuration=unique(birddat3.5$MaxDuration), durationClass=c("3", "5-6", "8-10", "8-10", "5-6"))

birddat3.5 <- merge(birddat3.5, distanceClass, by="Maxdist", all.x=T)
birddat3.5 <- merge(birddat3.5, durationClass, by="MaxDuration", all.x=T)
rm(birddat3)
```


### Aggregate to "total bird" count per survey instance


``` {r aggregate, eval=T}
sumABUND <- aggregate(birddat3.5$ABUND,  by=list(PKEY=birddat3.5$PKEY), FUN=sum)
colnames(sumABUND)[2] <- "sumABUND"

speciesCOUNT <- aggregate(birddat3.5$ABUND,  by=list(PKEY=birddat3.5$PKEY), FUN=length) 
colnames(speciesCOUNT)[2] <- "speciesCOUNT"

tmp <- merge(sumABUND, speciesCOUNT, by="PKEY")

birddat4 <- merge(tmp, birddat3.5[c("PKEY", "METHOD", "SS", "YYYY", "MaxDuration", "Maxdist", "durationClass", "distanceClass")], by="PKEY")

birddat4$PCODE <- unlist(lapply(strsplit(as.character(birddat4$SS), ":", fixed=T), function(x) {x[1]}))

birddat4 <- birddat4[!duplicated(birddat4),]
```









### Combine bird data with VRI data

``` {r}
bird_vri_dat_ready <- merge(birddat5, vri_bird_tempaligned[-which(colnames(vri_bird_tempaligned) %in% c("FID_BIRD", "VRIintersectLayer", "OBJECTID", "FID_VRI", "BirdLayer", "MAP_ID", "POLYGON_ID", "OPENING_IND", "OPENING_SOURCE", "POLYGON_AREA", "INPUT_DATE", "INTERPRETATION_DATE", "REFERENCE_YEAR", "ATTRIBUTION_BASE_DATE", "PROJECTED_DATE", "OPENING_ID", "ORG_UNIT_NO", "ORG_UNIT_CODE", "FD_PERCENT", "PL_PERCENT", "AT_PERCENT", "VRI.layer.polygon.ID",  "ToleratedLag", "LagExceedsTolerated", "VRI.layer.polygon.ID.PKEY", "YYYY", "SS"))], by="PKEY", all.x=T)
bird_vri_dat_ready$ForID <- with(bird_vri_dat_ready, paste(BecZone, SpeciesGroup, Age, Height, sep="."))
bird_vri_dat_ready <- bird_vri_dat_ready[sort(colnames(bird_vri_dat_ready))]

kable(bird_vri_dat_ready[sample(nrow(bird_vri_dat_ready), 10),c("ForID", "BecZone", "SpeciesGroup", "Age", "Height", "AgeClass_calc", "HeightClass_calc", "DisturbanceYear", "speciesCOUNT", "sumABUND")])
```

### Check if offsets are the same within a given survey method

``` {r}
methods <- unique(bird_vri_dat_ready$METHOD)

## function to look at unique offsets within a given method. Should have one value per row/method.
kable(do.call(rbind, lapply(methods, function(x) {
  unique(bird_vri_dat_ready[bird_vri_dat_ready$METHOD == x,]$Offset)
})))

```

``` {r}
cache("bird_vri_dat_ready")
```